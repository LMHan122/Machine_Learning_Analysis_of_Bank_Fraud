{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0688a081-65f3-45fb-951c-4a3690e463f8",
   "metadata": {},
   "source": [
    "## Data Understanding: Exploring the Dataset\n",
    "\n",
    "This notebook will explore the Credit Card Transactions dataset to identify potential feature issues fulfilling the Data Understanding phase of the CRISP-DM project planning framework. \n",
    "\n",
    "### Objectives:\n",
    "1. **Understand the Dataset**: Gain familiarity with the dataset structure, including feature types, distributions, and relationships.\n",
    "2. **Identify Potential Issues**:\n",
    "   - Missing or incomplete data\n",
    "   - Outliers or anomalies\n",
    "   - Features that may require transformation \n",
    "3. **Document Observations**: Note any data quality issues and potential corrective actions.\n",
    "\n",
    "The aim is to clearly understand the dataset and necessary preprocessing steps, ensuring readiness for the feature engineering and modeling stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f4e073-50f3-4c2e-8079-99a19f9980d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geodatasets import get_path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rapidfuzz import fuzz, process\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "578bfc45-7d55-448b-aada-0a8bb9925e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to local csv file\n",
    "data = r\"C:\\Users\\eelil\\OneDrive\\Desktop\\Capstone\\Machine_Learning_Analysis_of_Bank_Fraud\\data\\1\\credit_card_transactions.csv\"\n",
    "\n",
    "# making dataframe\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776aa07-0e39-4a04-b6ef-c6c4ef4a6197",
   "metadata": {},
   "source": [
    "I am working with a local copy of the CSV file instead of accessing the wandb artifact to ensure that any changes made during the data understanding phase remain temporary and do not affect the original data. When I start on the preprocessing and feature creation phase, I will access the wandb artifact. Additionally, I am not incorporating logging into this file, as this notebook will serve as my log for this phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50897b2d-5363-48bb-9329-f97cc0c40cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing the first 5 rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729c6ed-6a18-419c-b08b-4165bd3099f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd85354-e888-49cf-93e9-d449ca318f0a",
   "metadata": {},
   "source": [
    "### Column Descriptions and Initial Observations\n",
    "\n",
    "The dataset contains the following columns:\n",
    "\n",
    "1. **Unnamed**: Original index column, redundant in this analysis.\n",
    "2. **trans_date_trans_time**: Timestamp of the transaction.\n",
    "3. **cc_num**: Credit card number (hashed/anonymized).\n",
    "4. **merchant**: Merchant or store where the transaction occurred.\n",
    "5. **category**: Type of transaction.\n",
    "6. **amt**: Amount of the transaction.\n",
    "7. **first**: First name of the cardholder.\n",
    "8. **last**: Last name of the cardholder.\n",
    "9. **gender**: Gender of the cardholder.\n",
    "10. **street**: Address details of the cardholder.\n",
    "11. **city**: Address details of the cardholder.\n",
    "12. **state**: Address details of the cardholder.\n",
    "13. **zip**: Address details of the cardholder.\n",
    "14. **lat**: Geographical coordinates of the transaction.\n",
    "15. **long**: Geographical coordinates of the transaction.\n",
    "16. **city_pop**: Population of the city where the transaction occurred.\n",
    "17. **job**: Occupation of the cardholder.\n",
    "18. **dob**: Date of birth of the cardholder.\n",
    "19. **trans_num**: Unique transaction number.\n",
    "20. **unix_time**: Unix timestamp of the transaction.\n",
    "21. **merch_lat**: Geographical coordinates of the merchant.\n",
    "22. **merch_long**: Geographical coordinates of the merchant.\n",
    "23. **is_fraud**: Indicator of whether the transaction is fraudulent.\n",
    "24. **merch_zipcode**: Zip code of the merchant.\n",
    "\n",
    "**Please note, these column descriptions are taken directly from [Kaggle](https://www.kaggle.com/datasets/priyamchoksi/credit-card-transactions-dataset) (Choksi, n.d.).**    \n",
    "\n",
    "Based on the column descriptions and the initial inspection of the data (first five rows of the dataframe), the following columns will be removed:\n",
    "\n",
    "1. **Unnamed**: This column served as the original index and is redundant.\n",
    "\n",
    "2. **first**, **last**, **gender**, **street**, **zip**, **merch_zipcode**:\n",
    "   - **first** and **last** are not necessary for analysis, as the credit card number (`cc_num`) already identifies the account.\n",
    "   - **gender** is unlikely to contribute to identifying fraudulent transactions and could introduce bias or discrimination into the model.\n",
    "   - **unix_time** will be dropped if 'trans_data_trans_time' is complete.\n",
    "   - **street** is too specific for this project. I will be using city and state for customer's location.\n",
    "   - **zip**, **merch_zipcode** will be dropped for redundency if other location based columns are complete.\n",
    "\n",
    "**trans_num** will be retained to prevent identical values in other columns from mistakenly flagged as duplicates, and won't be adjusted unless there are duplicate values.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25708ece-f03a-42e3-ab48-8701e7a5dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnamed column\n",
    "df.drop(\n",
    "    df.columns[df.columns.str.contains(\"unnamed\", case=False)], axis=1, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158cdb5-4975-42be-8695-ad9762b5d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 'first', 'last', and 'gender'\n",
    "df.drop([\"first\", \"last\", \"gender\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d5541-25f0-4bea-a4bb-2baf8d9084ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of records and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54945cec-2ec4-4f66-9274-ba8995b93d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping any duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "# checking if the number of records changed\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570a940-c68b-4a2d-bc89-e736ac910df7",
   "metadata": {},
   "source": [
    "There were no duplicates in this dataset. However, I will add duplicate-checking in the data preparation phase to accommodate future datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca0cd0-3812-4179-b44d-1b526fd35ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c880ec-657a-4190-b7fa-8eda107971a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping redundant columns\n",
    "df.drop([\"street\", \"zip\", \"merch_zipcode\", \"unix_time\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6769734-ab16-4a32-9d54-b745aefe4504",
   "metadata": {},
   "source": [
    "### Based on the datatypes and null values:\n",
    "\n",
    "**Location Columns**\n",
    "Due to redundancy, several location columns ('street,' 'zip,' 'merch_zipcode) were dropped. \n",
    "- The latitude and longitude columns for merchants are complete and will be utilized in the next phase for merchant location, resulting in 'merch_zipcode' being dropped. This also removed all null values from the dataframe.\n",
    "- The 'street' column was dropped since 'city' and 'state' will represent the customer's location.\n",
    "\n",
    "**Unix Time Column**\n",
    "The 'unix_time' column was dropped for redundancy since 'trans_date_trans_time' is complete. I intend to make several new datetime columns.\n",
    "\n",
    "**Columns with Unusual Data Types** \n",
    "- trans_date_trans_time  |  object \n",
    "- merchant               |  object \n",
    "- category               |  object \n",
    "- city                   |  object   \n",
    "- state                  |  object  \n",
    "- job                    |  object  \n",
    "- dob                    |  object  \n",
    "- is_fraud               |  int64    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e7075-5013-447e-bd80-4e64ad338187",
   "metadata": {},
   "source": [
    "\n",
    "Will be changed to: \n",
    "1. **'trans_data_trans_time', 'dob'** - datetime\n",
    "2. **'merchant', 'category', 'city', 'state', 'job', 'is_fraud'** - category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ec057-e265-4443-8b8d-903e1762d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique values in each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31859e2d-61db-4fde-b291-457e690d2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing data types of some columns for easier plotting\n",
    "# first the datetime columns\n",
    "df[\"trans_date_trans_time\"] = pd.to_datetime(df[\"trans_date_trans_time\"])\n",
    "df[\"trans_date_trans_time\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d495c4c0-655a-4905-9ede-4b3615e47c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dob\"] = pd.to_datetime(df[\"dob\"])\n",
    "df[\"dob\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ccbeaa-2020-421f-b4f5-c21dc12b7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the category columns\n",
    "df[[\"category\", \"merchant\", \"job\", \"is_fraud\", \"state\", \"city\"]] = df[\n",
    "    [\"category\", \"merchant\", \"job\", \"is_fraud\", \"state\", \"city\"]\n",
    "].astype(\"category\")\n",
    "df[[\"category\", \"merchant\", \"job\", \"is_fraud\", \"state\", \"city\"]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946e672-9c20-4cfa-a02c-944970fc65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data types before plotting\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e17675f-529b-4a72-b175-c201e46476a4",
   "metadata": {},
   "source": [
    "## Column Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3979f9-d6f4-44dd-8e31-34e5d21a77d1",
   "metadata": {},
   "source": [
    "### Column - 'is_fraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b12931-b512-4772-8f29-6277478e9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping fraud accounts\n",
    "fraud = df.groupby(\"is_fraud\", observed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abfa3f6-f7f5-486e-916e-4e9e3784867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing what portion of the data is fraudulent transactions\n",
    "fraud_counts = fraud.size()\n",
    "ax = fraud_counts.plot(kind=\"bar\", rot=0, color=[\"blue\", \"red\"], figsize=(13, 6))\n",
    "\n",
    "plt.xlabel(\"Fraud\")\n",
    "plt.ylabel(\"Count in Millions\")\n",
    "ax.set_title(\"Transaction Counts: Fraud vs. Non-Fraud\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a722642-cb82-4345-9853-3cdc1e22889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = fraudulant transaction, 0 = non-fraudulant transaction\n",
    "fraud_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc593d-081b-491f-a26b-30494b976d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_percentages = (fraud_counts / fraud_counts.sum() * 100).round(2)\n",
    "fraud_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd2292-aaa9-4990-b5ea-c23f5c4efc97",
   "metadata": {},
   "source": [
    "**Less than 1% of the transactions are fraudulent.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793d249-aa1f-49f6-9ec4-b4b51f2a4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating how much the fraud transactions are\n",
    "fraud_amount = fraud[\"amt\"].sum()\n",
    "fraud_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548e2f5-1ac1-4bf6-b9d1-98f41e21f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fraud_amount.plot(kind=\"bar\", rot=0, color=[\"blue\", \"red\"], figsize=(13, 6))\n",
    "\n",
    "plt.xlabel(\"Fraud Classification\")\n",
    "plt.ylabel(\"Transaction Amount (Tens of Millions)\")\n",
    "ax.set_title(\"Transaction Amount: Fraud vs. Non-Fraud\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80970b2-62dd-4d87-b73c-184c015aad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_amount_per = (fraud_amount / fraud_amount.sum() * 100).round(2)\n",
    "fraud_amount_per"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494be88e-20ba-45e4-b429-25f0555a3939",
   "metadata": {},
   "source": [
    "**While it makes up over 4% of the transaction amount.** The 'is_fraud' column does not be adjusted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f50cda-04e9-4e41-b9c8-b5e80c788f92",
   "metadata": {},
   "source": [
    "### Column - 'amt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad722889-245b-4923-85c1-f6cf5f6011bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking further into transaction amount\n",
    "amt = df[\"amt\"]\n",
    "amt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d67f434-fac5-4d9c-9956-ae3370746f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for easier viewing\n",
    "print(\n",
    "    f\"Min Transactional Amount ${amt.min():,.2f} and Max Transactional Amount ${amt.max():,.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf5001-80df-4b2d-b823-6f19303fe8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying a logarithmic transformation to the amount column for better visualization in the boxplot\n",
    "amt_trans = np.log(amt[amt > 0])\n",
    "\n",
    "# boxplot\n",
    "plt.boxplot(amt_trans)\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.ylabel(\"Log-Transformed Amount\")\n",
    "plt.title(\"Boxplot of Log-Transformed Transaction Amounts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc88724f-ab38-460c-bd5c-4be58efabcad",
   "metadata": {},
   "source": [
    "This plot highlights a relatively large number of outliers at the higher end of the transaction amounts. No issues requiring changes to the 'amt' column were identified at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aff5a6-0bfe-473a-b923-07de1d369ebb",
   "metadata": {},
   "source": [
    "### Column - 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b8493-d9a2-48cd-8c53-4c991e166149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting category frequency\n",
    "df[\"category\"].value_counts().plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(10, 6),\n",
    "    ylabel=\"Number of Transactions\",\n",
    "    title=\"Transaction Frequency by Category\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0428ed2a-c7aa-4d42-933d-78c3e7128674",
   "metadata": {},
   "source": [
    "The 'category' column contains 14 unique values representing transaction types. Based on the names:\n",
    "\n",
    "1. **Online Transactions:** Categories such as 'shopping_net', 'misc_net', and 'grocery_net' include 'net', likely indicating online transactions.\n",
    "2. **In-Person Transactions:** Categories such as 'grocery_pos', 'shopping_pos', 'misc_pos', and 'gas_transport' include 'pos' or are typical in-person transactions (e.g., gas purchases).\n",
    "3. **Unknown or Mixed:** Categories like 'home', 'kids_pets', 'entertainment', 'food_dining', 'personal_care', 'health_fitness', and 'travel' lack clear indicators and could represent either online or in-person transactions.\n",
    "\n",
    "Additional research on Kaggle yielded no further details about the column's interpretation. This column will not be adjusted further, but ideas have been generated for potential new columns to be added during preprocessing.\n",
    "\n",
    "### New Column Ideas\n",
    "**Online/In-Person/Mixed Indicator**\n",
    "- Name: 'transaction_type'\n",
    "- Type: Category\n",
    "- Values: 0: Unknown/Mixed, 1: Online, 2: In-Person\n",
    "\n",
    "**Distance From Transaction to Card Holder**\n",
    "- Distance between the transaction's latitude/longitude and the user's city/state coordinates\n",
    "- Name: 'transactional_distance'\n",
    "- Type: Float\n",
    "\n",
    "**Merchant Distance**\n",
    "- Distance between the merchant's latitude/longitude (merch_long, merch_lat) and the user's city/state.\n",
    "- Name: 'merch_distance'\n",
    "- Type: Float\n",
    "\n",
    "Processing resources and time will determine if columns are added. This will be researched further during feature creation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dbfba1-518b-40ab-a82f-88aae1c770d3",
   "metadata": {},
   "source": [
    "### Location Columns - 'lat', 'long', 'merch_lat', 'merch_long', 'city', 'state'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d81f31-114c-4d07-a3ae-205c1b9b036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapefiles used for this process was downloaded from\n",
    "# https://www.sciencebase.gov/catalog/item/5d150464e4b0941bde5b7654\n",
    "map_file = r\"/map/US_Map_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468d841-068c-4b89-b18e-9f0becc885ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the ranges\n",
    "lat_long_columns = [\"lat\", \"long\", \"merch_lat\", \"merch_long\"]\n",
    "df[lat_long_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba1f2b-555e-4659-813f-f967e97b7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing the min and max values for each column\n",
    "for col in lat_long_columns:\n",
    "    print(f\"Smallest value {col} = {df[col].min()}\")\n",
    "    print(f\"Largest value {col} = {df[col].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83b95b-0ff4-4ed1-93f2-9370626a1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the transaction locations using 'long' and 'lat' columns\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.long, df.lat))\n",
    "map = gpd.read_file(map_file)\n",
    "ax = map.plot(color=\"lightgrey\", edgecolor=\"black\", figsize=(15, 15))\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "gdf.plot(ax=ax, color=\"red\", markersize=1)\n",
    "plt.xlim(-170, -65)\n",
    "ax.set_title(\"Transaction Locations\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f13cdb-414e-4607-a5da-27c8d0e821e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting merchant locations using 'merch_long' and 'merch_lat' columns\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.merch_long, df.merch_lat))\n",
    "map = gpd.read_file(map_file)\n",
    "ax = map.plot(color=\"lightgrey\", edgecolor=\"black\", figsize=(15, 15))\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "gdf.plot(ax=ax, color=\"blue\", markersize=1)\n",
    "plt.xlim(-170, -65)\n",
    "ax.set_title(\"Merchant Locations\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f7332-27bd-4b16-98b4-c280af8d02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# referencing the unique values for these columns\n",
    "df[lat_long_columns].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477b798-b46f-487c-9bef-d274e6fb1baa",
   "metadata": {},
   "source": [
    "The data appears to have been anonymized or artificially generated, as indicated by the square clustering observed on the Merchant Locations map and the relatively low number of unique values in the 'lat' and 'long' columns. No adjustments will be made to these columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3bee3d-fd61-496e-952e-6d26bea84fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigating customer location columns\n",
    "cust_loc = [\"city\", \"state\"]\n",
    "df[cust_loc].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca7dd7-805b-4aa4-bfaa-1b79b1287e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking state code values to see why it is 51\n",
    "states = df[\"state\"].unique()\n",
    "states = states.tolist()\n",
    "states.sort()\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5fde58-66c9-49f3-af69-62cc5dbc3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating unique city, state pair\n",
    "loc_pairs = df[[\"city\", \"state\"]].drop_duplicates()\n",
    "loc_pairs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0dc23f-26f5-411f-b583-fcfceaacb6bc",
   "metadata": {},
   "source": [
    "- The 'state' column has 50 US states and DC for Washington DC.\n",
    "- The 'city' column has 894 unique values.\n",
    "- There are 928 unique value pairs representing customer locations, so some cities share names, which might look like a false pattern. \n",
    "- There are 983 unique customer credit card numbers, so some cities have multiple customers.\n",
    "\n",
    "#### New Column Ideas\n",
    "**Latitude and Longitude for Customer's City**\n",
    "- Name: 'cust_lat' & 'cust_long'\n",
    "- Type: Float\n",
    "\n",
    "Create two new columns, which will be populated based on the 'city' and 'state' pair vaules. Once created, the 'city' and 'state' will be dropped after. No further changes will be made to the 'state' column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007e936-7dd3-483f-a657-1d4bea69be78",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bcecb4-6fad-4c57-85cb-df8766feda05",
   "metadata": {},
   "source": [
    "### Column - 'trans_date_trans_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583feaad-b446-4a07-9eaf-a7a33e3732b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming 'trans_date_trans_time' column to something easier\n",
    "df.rename(columns={\"trans_date_trans_time\": \"trans_dt\"}, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387607c-c45f-481e-b79b-81ff5b856587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating date ranges\n",
    "(df[\"trans_dt\"].min(), df[\"trans_dt\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c56d45-fa93-40d1-a40b-be16bc4d7624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a quick and easy viz of transactions over time\n",
    "# using bins=18 so there can be approximately 1 bin for each month\n",
    "# this isn't accurately separated by month, using this for ideas\n",
    "n, bins, patches = plt.hist(df[\"trans_dt\"], bins=18)\n",
    "\n",
    "labels = np.arange(1, 19)\n",
    "midpoints = (bins[:-1] + bins[1:]) / 2\n",
    "plt.xticks(ticks=midpoints, labels=labels)\n",
    "\n",
    "plt.title(\"Transaction Volume by Month\")\n",
    "plt.ylabel(\"Number of Transactions\")\n",
    "plt.xlabel(\"Aprox Month\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7856b-9e2e-48b4-b620-04e2adcdc4a3",
   "metadata": {},
   "source": [
    "From this plot, we can roughly see that transaction volume can vary from month to month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96771198-e55e-4ea2-8dba-a57f367f2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"trans_dt\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d01c5f-f0a8-41b6-bfa4-dc002cab297e",
   "metadata": {},
   "source": [
    "  \n",
    "The 'trans_dt' column has a lot of data packed into every field. The format is Year - Month - Day - Hour - Minute - Second. I want to create new columns, afterwhich 'trans_dt' can be dropped.\n",
    "\n",
    "### New Column Ideas\n",
    "**Separate fields for Date, Year, Month, Day**\n",
    "- Name: 'date', 'year', 'month', 'day'\n",
    "- Type: Various\n",
    "- To analyze specific transaction patterns by specific date and time components. \n",
    "\n",
    "**Week & Quarter**\n",
    "- Name: 'week' & 'quarter'\n",
    "- Type: Category\n",
    "- To analyze seasonal patterns and time-related outliers. \n",
    "\n",
    "**Running Transaction Averages and Counts**\n",
    "- Name: 'trans_by_last_hr','trans_by_last_day', 'amt_last_hour', 'amt_last_day'\n",
    "- Type: Float\n",
    "- To track spending patterns for individual customers, enabling the detection of unusual spikes in transaction frequency or amount. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08629f-dcf0-4d19-8e39-5c8ff6e04f69",
   "metadata": {},
   "source": [
    "### Column - 'cc_num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55e9e7-56a6-44d4-ae63-5fe18bfd76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the number of transaction for each cc account\n",
    "cc_counts = df.groupby(\"cc_num\", observed=True).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec88ec3-dcc2-41b7-9256-39df1d14b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of unique accounts\n",
    "df[\"cc_num\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9f777-54bb-4d92-a690-bb41f02d7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_counts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba73878-f8f5-41fa-a033-cc4f320a38e6",
   "metadata": {},
   "source": [
    "This dataset has records for 983 customer, and number of transactions a single customer makes ranges from 7 to 3,123. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384e1b4-afd9-45b7-84f2-a52a9f1a5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the values\n",
    "sorted_cc = cc_counts.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9872984d-3b1a-4096-8205-ad1a01aec685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the number of transactions for low to high to see\n",
    "# if there are typical transaction rates\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.bar(range(len(sorted_cc)), sorted_cc)\n",
    "plt.xlabel(\"CC Account\")\n",
    "plt.ylabel(\"Number of Transactions\")\n",
    "plt.title(\"Number of Transactions for Each Account\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044d31df-aaa4-4c43-a36a-633751a79d6e",
   "metadata": {},
   "source": [
    "The 'cc_num' column reveals that transaction frequencies tend to cluster together. No changes will be made to the 'cc_num' column, as it is needed for identifying individual customers. Plans to use this column for creating new features, such as transaction patterns and spending behaviors, have already been outlined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e6503a-a3f8-48b6-b5c0-bc76db5cf78d",
   "metadata": {},
   "source": [
    "### Column - 'merchant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e52b25-7722-4798-80e6-60a3cbd4605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a variable of merchant names and finding the number of merchants\n",
    "merchants = df[\"merchant\"].unique()\n",
    "len(merchants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3097578-5e79-4931-8559-ef952700e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the number of transactions for each merchant\n",
    "merchant_count = df[\"merchant\"].value_counts()\n",
    "merchant_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee4d05-3a3e-438c-93aa-cc26df4cfcee",
   "metadata": {},
   "source": [
    "The range of transaction frequency by merchant range from 727 to 4403. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f14e0fd-444e-4f39-bc48-436edac3e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the high and low monitary amount per merchant\n",
    "merchant_amount = df.groupby(\"merchant\", observed=True)[\"amt\"].sum()\n",
    "merchant_amount = merchant_amount.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530387d0-c8a8-49db-be4a-71c3618d4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ten merchants with the lowest amount\n",
    "low = merchant_amount.head(10)\n",
    "low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba493c57-38c4-4669-9e01-b8e6ed501f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ten merchants with the highest amounts\n",
    "high = merchant_amount.tail(10)\n",
    "high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb9a6a-87e4-44ea-8d67-01dc9d5522bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot showing the range\n",
    "plt.boxplot(merchant_amount)\n",
    "plt.xlabel(\"Merchants\")\n",
    "plt.ylabel(\"Transaction Amount (USD)\")\n",
    "plt.title(\"Transaction Amount Distribution Across Merchants\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b5412-663f-44d1-8338-eaf7c46a7323",
   "metadata": {},
   "source": [
    "This plot shows that merchant transaction amounts can vary significantly from one merchant to the next, as does the number of transactions per merchant. This column will not be adjusted at this time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830a0bb4-eddc-494f-9ce8-38d9f4b31939",
   "metadata": {},
   "source": [
    "### Column - 'city_pop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1da241-9d4e-4888-883e-a373e684b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking unique values\n",
    "pop_values = df[\"city_pop\"].drop_duplicates()\n",
    "pop_values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df62d8-33eb-458f-8be9-677fd95917c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking unique city, state, city_pop values\n",
    "pop_triad = df[[\"city\", \"state\", \"city_pop\"]].drop_duplicates()\n",
    "pop_triad.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ede3d-dbc0-4c28-8f01-85851fb3cf9c",
   "metadata": {},
   "source": [
    "There are 879 unique city population values but 928 unique customer locations, so some cities have the same population value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350378c-e8a6-42ba-8eea-5749c0920de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the low and high city populations\n",
    "pop_city = pop_triad.sort_values(by=\"city_pop\")\n",
    "pop_city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a634d64d-6b60-4524-8c0b-45a537e9f50f",
   "metadata": {},
   "source": [
    "The city_pop column displays a wide variation, with values ranging from 23 to 2,906,700. Concerned about potential inaccuracies, I conducted further investigation. A cursory search for Notrees, Texas, found its population to be approximately 20 in 2009, aligning closely with the dataset. However, another search for West Bethel, ME, revealed a significant discrepancy, as its population was 2,504 according to [Wikipedia](https://en.wikipedia.org/wiki/Bethel,_Maine). Similar inconsistencies were found for other cities. Given the unreliable nature of the city_pop data, I have decided to drop this column from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262818a2-7fbd-46a6-94a2-735497d2747e",
   "metadata": {},
   "source": [
    "### Column - 'job'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89923f5d-1fa6-4651-94ed-6f19a09e9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many unique values are in the 'job' column\n",
    "df[\"job\"] = df[\"job\"].str.lower().str.strip()\n",
    "df[\"job\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370dba5a-5ceb-42f6-a36f-5163d01d0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing data down to one transaction per account and job title\n",
    "jobs_db = df[[\"cc_num\", \"job\"]].drop_duplicates()\n",
    "jobs_db = jobs_db.sort_values(by=\"job\")\n",
    "jobs_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c36a0-517d-42e4-8367-aab8ce5f084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing how many customers have the same job title\n",
    "job_count = jobs_db[\"job\"].value_counts()\n",
    "job_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781008b4-cb5a-49c3-ba43-69e940bfcc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each job title\n",
    "jobs = jobs_db[\"job\"].drop_duplicates()\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff22fb4-8b1f-486f-8d0c-445f2f43889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many skills have similar names using rapid fuzz\n",
    "similar_jobs = []\n",
    "\n",
    "for i, job in enumerate(jobs):\n",
    "    matches = process.extract(\n",
    "        job, jobs[i + 1 :], scorer=fuzz.token_sort_ratio, limit=10\n",
    "    )\n",
    "    for match in matches:\n",
    "        if match[1] >= 80:  # has similarity score of at least 80\n",
    "            similar_jobs.append((job, match[0], match[1]))\n",
    "\n",
    "len(similar_jobs)  # seeing how many matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235dd76d-810d-4bbf-86c4-a0032c792121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the matching jobs\n",
    "similar_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b28f01-f139-4acc-bfe6-8e02af134564",
   "metadata": {},
   "source": [
    "While the job names are very similar, the jobs with a score lower than 95 seem different, while the ones with a score higher than 95 seem to be the same job but written slightly differently. I will adjust the similarity score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5081a9-55b8-479d-b7e3-b0a83880fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the similarity score\n",
    "similar_jobs = []\n",
    "\n",
    "for i, job in enumerate(jobs):\n",
    "    matches = process.extract(\n",
    "        job, jobs[i + 1 :], scorer=fuzz.token_sort_ratio, limit=10\n",
    "    )\n",
    "    for match in matches:\n",
    "        if match[1] >= 95:  # has similarity score of at least 95\n",
    "            similar_jobs.append((job, match[0], match[1]))\n",
    "\n",
    "len(similar_jobs)  # seeing how many matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386ee9b-50e3-4c40-944e-703e659e35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720fb07-0374-4165-988d-36d0bdd48c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcbee9a-3e1f-4bad-a0cd-bbe631c6e68a",
   "metadata": {},
   "source": [
    "The dataset has 494 unique job titles, with each title appearing one to six times. After sorting the column values, I noticed similar but slightly different job titles. I ran RapidFuzz with a similarity threshold of 80 to identify potential matches, but this resulted in overly broad groupings. To improve accuracy, I changed the similarity threshold to 95, which reduced the matches from 144 to 81. During the preprocessing phase, I plan to replace the less common variations of job titles with the most frequently used version for standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8217a677-c4a6-483d-ba2f-aefdf219b461",
   "metadata": {},
   "source": [
    "### Column - 'dob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72f2e1-c7a6-46aa-8451-3adb511202c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the range of values for date of birth\n",
    "df[\"dob\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec249957-060d-421b-998c-078f8b46f5c9",
   "metadata": {},
   "source": [
    "One visible issue is that the maximum value for the date of birth is 2005-01-29. That would make the cardholder around 14 to 15 at the time of the transaction. This could be an indicator of fraud or an incorrect value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32e6af-598a-4086-87e8-e4e10070cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping and sorting the birthday values for plotting\n",
    "birthdays = df[[\"cc_num\", \"dob\"]].drop_duplicates()\n",
    "sorted_dob = birthdays.sort_values(by=\"dob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065bfb9b-09c1-42dd-8d8e-fb5ba2a84cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a year and decade column for easier plotting\n",
    "birthdays[\"year\"] = birthdays[\"dob\"].dt.year\n",
    "birthdays[\"decade\"] = (birthdays[\"year\"] // 10) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b998104-c008-41d1-ba4a-39e5c97e35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping every ten years together\n",
    "decade_counts = birthdays.groupby(\"decade\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a539ae-a9fc-4834-9186-c26d5ef88ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_counts.plot(kind=\"bar\")\n",
    "plt.title(\"Number of Birthdays by Decade\")\n",
    "plt.xlabel(\"Decade\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7987c1-8821-40ab-9139-9623d5868db7",
   "metadata": {},
   "source": [
    "This plot highlights that the majority of account holders were born between the 1960s and 1990s. Birthdays at either extreme could indicate potential fraud, especially for account holders under 18 at the time of the transaction.\n",
    "\n",
    "**New Column Idea**\n",
    "- Name: 'age_at_trans'\n",
    "- Type: Float\n",
    "- This column will have the customer's age (in years) at the time of the transaction to see if it is an indicator of fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434d22b-a09e-4295-974a-47f2ba4333d8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12eef1-90fa-4c76-886d-497110695174",
   "metadata": {},
   "source": [
    "I explored the dataset to understand its structure, quality, and come up with potential preprocessing and feature engineering ideas. Key takeaways included:\n",
    "\n",
    "---\n",
    "\n",
    "#### **Data Cleaning and Preparation**\n",
    "\n",
    "1. **Column Renaming**\n",
    "\n",
    "- 'trans_date_trans_time' will be renamed to 'trans_dt'.\n",
    "\n",
    "  \n",
    "2. **Columns to Drop**  \n",
    "- **Before feature creation**: 'unnamed', 'first', 'last', 'gender', 'street', 'zip', 'merch_zipcode', 'unix_time', and 'city_pop'. \n",
    "- **After creating features**: 'city'. 'state', 'trans_dt', and 'dob'. \n",
    "\n",
    "  \n",
    "3. **Data Type Adjustments**:  \n",
    "- Convert to datetime: 'trans_dt', 'dob'.\n",
    "- Convert to category: 'merchant', 'category', 'city', 'state', 'job', 'is_fraud'.\n",
    "\n",
    "  \n",
    "4. **Duplicates**:  \n",
    "- No duplicate rows were found in the dataset.\n",
    "\n",
    "\n",
    "---\n",
    "  \n",
    "#### **Takeaways**\n",
    "\n",
    "1. **Fraudulent Transactions**  \n",
    "- Less than 1% of transactions are fraudulent but account for over 4% of the transaction amount.\n",
    "- 'is_fraud' column will not be adjusted.\n",
    "\n",
    "2. **Transaction Amounts (amt)**:  \n",
    "- Range: \\\\$1.00 to \\\\$28,948.90.\n",
    "- The column contains outliers at the higher end, but no adjustments will be made. \n",
    "\n",
    "3. **Transaction Categories**:  \n",
    "- 14 unique categories with potential to classify transactions as online, in-person, or mixed based on naming conventions.\n",
    "- No further changes to the column, but a new \"transaction_type\" column will be added.\n",
    "\n",
    "4. **Location Data**:  \n",
    "- Latitude and longitude values for both transactions and merchants suggest anonymization due to square clustering or a low number of unique values.\n",
    "- **Range of values**:\n",
    "    - **Transaction** latitudes: 20.0271 to 66.6933, longitudes: -165.6723 to -67.9503.\n",
    "    - **Merchant** latitudes: 19.027785 to 67.510267, longitudes: -166.671242 to -66.950902.\n",
    "- Columns remain unchanged, but new features such as 'merch_distance' will be added.\n",
    "\n",
    "5. **City Population (city_pop)**:  \n",
    "- Values range from 23 to 2,906,700 across 879 unique entries. However, several inconsistencies were identified during validation.\n",
    "- The column will be dropped due to unreliablity.\n",
    "\n",
    "7. **Job Titles (job)**:  \n",
    "- 494 unique job titles with inconsistencies in naming conventions.\n",
    "- During preprocessing, less common variations will be replaced with their most frequently used counterparts using a similarity threshold of 95 in RapidFuzz.\n",
    "\n",
    "8. **Birth Dates (dob)**:  \n",
    "- Majority of account holders were born between the 1960s and 1990s.\n",
    "- Extreme birth dates could indicate potential fraud, especially for account holders under 18 at the time of the transaction.\n",
    "\n",
    "9. **Credit Card Numbers (cc_num)**:  \n",
    "- Range: 7 to 3,123 transactions per customer.\n",
    "- No adjustments planned, as this column is needed for identifying patterns in spending behaviors.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Potential New Features**\n",
    "- **Transaction Features**: 'transaction_type', 'trans_by_last_hr', 'trans_by_last_day', 'amt_last_hour', 'amt_last_day'\n",
    "- **Location Features**: 'merch_distance', 'cust_lat', 'cust_long'.\n",
    "- **Time Features**: 'date', 'year', 'month', 'day', 'week', 'quarter'.\n",
    "- **Age Feature**: \"age_at_trans\", representing the customer's age at the time of the transaction (float).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Transaction Timeline**\n",
    "- **Data spans**: January 1, 2019, to June 21, 2020.\n",
    "- **Counts**:\n",
    "  - Customers: 983.\n",
    "  - Merchants: 693.\n",
    "- **Transaction frequency**:\n",
    "  - Customers: 7 to 3,123 transactions.\n",
    "  - Merchants: 727 to 4,403 transactions.\n",
    "\n",
    "This comprehensive understanding of the dataset lays the foundation for effective preprocessing, feature engineering, and model development in subsequent phases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ce075-d311-4690-85f1-8481591ed77c",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c164dcb-2a1d-498e-a97f-84f8dee305a0",
   "metadata": {},
   "source": [
    "Choksi, P. (n.d.). Credit card transactions dataset: Using transactional data for financial analysis and fraud detection. Kaggle. Retrieved November 21, 2024, from https://www.kaggle.com/datasets/priyamchoksi/credit-card-transactions-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e4abd2-b63c-4c57-8e0f-6cfd28d45467",
   "metadata": {},
   "source": [
    "National Atlas of the United States. (2014). 1:1,000,000-Scale State Boundaries of the United States [Vector digital data]. Rolla, MO: National Atlas of the United States. Retrieved from https://www.sciencebase.gov/catalog/item/581d052de4b08da350d524e5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d37c6-715d-4536-9ea1-b9647e959541",
   "metadata": {},
   "source": [
    "Wikipedia contributors. (n.d.). Bethel, Maine. In Wikipedia. Retrieved December 6, 2024, from https://en.wikipedia.org/wiki/Bethel,_Maine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
