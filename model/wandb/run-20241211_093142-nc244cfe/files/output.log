wandb: Downloading large artifact train_data:latest, 72.86MB. 1 files...
wandb:   1 of 1 files downloaded.
Done. 0:0:0.2
2024-12-11 09:31:45,079 Dataset loaded successfully with shape: (1056847, 28)
2024-12-11 09:31:45,079 Preprocessing data
2024-12-11 09:31:45,079 Dropping columns
2024-12-11 09:31:45,122 Dropping Nulls
2024-12-11 09:31:45,170 Encoding categorical variables
2024-12-11 09:31:46,794 Logistic Regression model with class_weight='balanced'
2024-12-11 09:31:46,795 Training LogisticRegression(class_weight='balanced', random_state=10)
C:\Users\eelil\.conda\envs\Machine_Learning_Analysis_of_Bank_Fraud\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression

2024-12-11 09:32:08,445 Evaluating model
2024-12-11 09:32:08,474 Precision: 0.07867256637168142
2024-12-11 09:32:08,502 Recall: 0.7439330543933055
2024-12-11 09:32:08,531 F1 score: 0.142296918767507
2024-12-11 09:32:08,548 AUC: 0.8470170922794262
2024-12-11 09:32:08,549 Total time to train and evaluate LogisticRegression(class_weight='balanced', random_state=10): 21.75438952445984
2024-12-11 09:32:08,549 Saving model LogisticRegression to a pickle file.
2024-12-11 09:32:08,550 Uploading LogisticRegression.pkl to WandB.
2024-12-11 09:32:08,842 Random Forest Classifier with 250 trees - rest default parameters.
2024-12-11 09:32:08,844 Training RandomForestClassifier(n_estimators=250, random_state=10)
2024-12-11 09:43:51,924 Evaluating model
2024-12-11 09:43:51,954 Precision: 0.9950900163666121
2024-12-11 09:43:51,984 Recall: 0.5087866108786611
2024-12-11 09:43:52,014 F1 score: 0.6733111849390919
2024-12-11 09:43:52,033 AUC: 0.754386116091069
2024-12-11 09:43:52,033 Total time to train and evaluate RandomForestClassifier(n_estimators=250, random_state=10): 703.1890161037445
2024-12-11 09:43:52,033 Saving model RandomForestClassifier to a pickle file.
2024-12-11 09:43:52,192 Uploading RandomForestClassifier.pkl to WandB.
2024-12-11 09:43:52,781 XGB model with gbtree. eta=0.3, max_depth=5, and GPU.
2024-12-11 09:43:52,783 Training XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cuda', early_stopping_rounds=None,
              enable_categorical=False, eta=0.3, eval_metric=None,
              feature_types=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=None, num_parallel_tree=None, ...)
Traceback (most recent call last):
  File "C:\Users\eelil\OneDrive\Desktop\Capstone\Machine_Learning_Analysis_of_Bank_Fraud\model\train_all_models.py", line 31, in <module>
    train_evaluate_model(xgb_model, X_train, y_train, X_test, y_test, run)
  File "C:\Users\eelil\OneDrive\Desktop\Capstone\Machine_Learning_Analysis_of_Bank_Fraud\model\shared_utils.py", line 81, in train_evaluate_model
    model.fit(X_train, y_train)
  File "C:\Users\eelil\.conda\envs\Machine_Learning_Analysis_of_Bank_Fraud\Lib\site-packages\xgboost\core.py", line 726, in inner_f
    return func(**kwargs)
           ^^^^^^^^^^^^^^
  File "C:\Users\eelil\.conda\envs\Machine_Learning_Analysis_of_Bank_Fraud\Lib\site-packages\xgboost\sklearn.py", line 1491, in fit
    raise ValueError(
ValueError: Invalid classes inferred from unique values of `y`.  Expected: [     0      1      2 ... 778983 778984 778985], got [-168.0903536 -166.666179 -166.661968 ... 25179.119999999995 25453.39
 26760.32]
